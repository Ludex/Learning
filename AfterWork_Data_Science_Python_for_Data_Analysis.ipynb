{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ludex/Learning/blob/main/AfterWork_Data_Science_Python_for_Data_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNodc6SRc-as"
      },
      "source": [
        "<font color=\"blue\">To use this notebook on Colaboratory, you will need to make a copy of it. Go to File > Save a Copy in Drive. You can then use the new copy that will appear in the new tab.</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFxpc1GNbCuw"
      },
      "source": [
        "# AfterWork Data Science: Python for Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcxusFFvAC4A"
      },
      "source": [
        "## 1. Importing our Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH7mXeCSkq0h"
      },
      "source": [
        "### Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iv0IIHuFkFnC"
      },
      "outputs": [],
      "source": [
        "# Example 1\n",
        "# ---\n",
        "# Let's first import the pandas library. \n",
        "# We will use this library to perform analysis and manipulation.\n",
        "# ---\n",
        "# Hint: pandas as pd\n",
        "# ---\n",
        "#\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_-wn-gNt8_0R"
      },
      "outputs": [],
      "source": [
        "# Example 2\n",
        "# ---\n",
        "# Let's import the numpy library for performing scientific computations.\n",
        "# ---\n",
        "# Hint i.e. numpy as np\n",
        "# ---\n",
        "# \n",
        "import numpy as np      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQKL2Y8uksQX"
      },
      "source": [
        "### <font color=\"green\">Challenges</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kPSzvlvzkvla"
      },
      "outputs": [],
      "source": [
        "# Challenge 1\n",
        "# ---\n",
        "# Question: Import the matplotlib library for data visualisations.\n",
        "# ---\n",
        "# Hint: matplotlib.pyplot as plt\n",
        "# ---  \n",
        "# YOUR CODE GOES BELOW\n",
        "#\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ExruDi-ekvZg"
      },
      "outputs": [],
      "source": [
        "# Challenge 2\n",
        "# ---\n",
        "# Question: Import the seaborn library for rich data visualisations.\n",
        "# ---\n",
        "# Hint: seaborn as sns\n",
        "# ---  \n",
        "# Hint\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "#\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2e7YkLzWW0G"
      },
      "source": [
        "## 2. Loading Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz-KdKO3fLjt"
      },
      "source": [
        "### Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "356YUryNfTqK"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal_length  sepal_width  petal_length  petal_width         species\n",
              "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
              "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
              "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
              "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
              "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
              "..            ...          ...           ...          ...             ...\n",
              "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
              "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
              "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
              "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
              "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
              "\n",
              "[150 rows x 5 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 1\n",
        "# ---\n",
        "# We can load a dataset from a csv file (accessible via URL) \n",
        "# then store it in a tabular form: a dataframe as shown below. \n",
        "# ---\n",
        "# Dataset URL = http://bit.ly/IrisDataset\n",
        "# ---\n",
        "# \n",
        "\n",
        "# Loading the dataset\n",
        "iris_df = pd.read_csv(\"http://bit.ly/IrisDataset\")\n",
        "\n",
        "# Printing the dataset\n",
        "iris_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "v4tuI2ixes3k"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rank</th>\n",
              "      <th>Country</th>\n",
              "      <th>Population</th>\n",
              "      <th>Year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>China</td>\n",
              "      <td>1380914176</td>\n",
              "      <td>2019 (Est.)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>India</td>\n",
              "      <td>1311559168</td>\n",
              "      <td>2019 (Est.)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>United States of America</td>\n",
              "      <td>333928672</td>\n",
              "      <td>2019 (Est.)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Indonesia</td>\n",
              "      <td>265253184</td>\n",
              "      <td>2019 (Est.)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Brazil</td>\n",
              "      <td>220632960</td>\n",
              "      <td>2019 (Est.)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>224</td>\n",
              "      <td>Cook Islands</td>\n",
              "      <td>8799</td>\n",
              "      <td>2019 (Est.)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>225</td>\n",
              "      <td>Saint Helena</td>\n",
              "      <td>7852</td>\n",
              "      <td>2019 (Est.)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>226</td>\n",
              "      <td>Saint BarthÃ©lemy</td>\n",
              "      <td>7140</td>\n",
              "      <td>2019 (Est.)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226</th>\n",
              "      <td>227</td>\n",
              "      <td>Saint Pierre and Miquelon</td>\n",
              "      <td>5409</td>\n",
              "      <td>2019 (Est.)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>228</td>\n",
              "      <td>Montserrat</td>\n",
              "      <td>5342</td>\n",
              "      <td>2019 (Est.)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>228 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Rank                    Country  Population         Year\n",
              "0       1                      China  1380914176  2019 (Est.)\n",
              "1       2                      India  1311559168  2019 (Est.)\n",
              "2       3   United States of America   333928672  2019 (Est.)\n",
              "3       4                  Indonesia   265253184  2019 (Est.)\n",
              "4       5                     Brazil   220632960  2019 (Est.)\n",
              "..    ...                        ...         ...          ...\n",
              "223   224               Cook Islands        8799  2019 (Est.)\n",
              "224   225               Saint Helena        7852  2019 (Est.)\n",
              "225   226           Saint BarthÃ©lemy        7140  2019 (Est.)\n",
              "226   227  Saint Pierre and Miquelon        5409  2019 (Est.)\n",
              "227   228                 Montserrat        5342  2019 (Est.)\n",
              "\n",
              "[228 rows x 4 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 2\n",
        "# ---\n",
        "# Lets create a dataframe from an xlsx file accessed from a URL as shown.\n",
        "# ---\n",
        "# Dataset URL = http://bit.ly/WorldPopulationDataset1\n",
        "# ---\n",
        "# Hint: This is a file in excel format.\n",
        "# ---\n",
        "# \n",
        "world_df = pd.read_excel(\"http://bit.ly/WorldPopulationDataset1\") \n",
        "world_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5W3kEz7eshu"
      },
      "outputs": [],
      "source": [
        "# Example 3\n",
        "# ---\n",
        "# Let's see how we can create a dataframe from an uploaded local CSV file. \n",
        "# ---\n",
        "# Download URL = http://bit.ly/CitiesDataset1 \n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Xpt8zo_8ncaE"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/workspace/Learning/AfterWork_Data_Science_Python_for_Data_Analysis.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ludex-learning-dscr350v51k.ws-eu53.gitpod.io/workspace/Learning/AfterWork_Data_Science_Python_for_Data_Analysis.ipynb#ch0000015vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m# Run the following code which will help us upload our downlaoaded file. \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ludex-learning-dscr350v51k.ws-eu53.gitpod.io/workspace/Learning/AfterWork_Data_Science_Python_for_Data_Analysis.ipynb#ch0000015vscode-remote?line=1'>2</a>\u001b[0m \u001b[39m# Then select the choose files box in the output and afterwards select the desired file.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ludex-learning-dscr350v51k.ws-eu53.gitpod.io/workspace/Learning/AfterWork_Data_Science_Python_for_Data_Analysis.ipynb#ch0000015vscode-remote?line=2'>3</a>\u001b[0m \u001b[39m# ---\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ludex-learning-dscr350v51k.ws-eu53.gitpod.io/workspace/Learning/AfterWork_Data_Science_Python_for_Data_Analysis.ipynb#ch0000015vscode-remote?line=3'>4</a>\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ludex-learning-dscr350v51k.ws-eu53.gitpod.io/workspace/Learning/AfterWork_Data_Science_Python_for_Data_Analysis.ipynb#ch0000015vscode-remote?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m files\n\u001b[1;32m      <a href='vscode-notebook-cell://ludex-learning-dscr350v51k.ws-eu53.gitpod.io/workspace/Learning/AfterWork_Data_Science_Python_for_Data_Analysis.ipynb#ch0000015vscode-remote?line=5'>6</a>\u001b[0m files\u001b[39m.\u001b[39mupload()\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
          ]
        }
      ],
      "source": [
        "# Run the following code which will help us upload our downlaoaded file. \n",
        "# Then select the choose files box in the output and afterwards select the desired file.\n",
        "# ---\n",
        "#\n",
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "W4-p6gqkoD7l"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'cities (6).csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/workspace/Learning/AfterWork_Data_Science_Python_for_Data_Analysis.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ludex-learning-dscr350v51k.ws-eu53.gitpod.io/workspace/Learning/AfterWork_Data_Science_Python_for_Data_Analysis.ipynb#ch0000016vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m# Upon selecting and uploading the given file from our computer, \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ludex-learning-dscr350v51k.ws-eu53.gitpod.io/workspace/Learning/AfterWork_Data_Science_Python_for_Data_Analysis.ipynb#ch0000016vscode-remote?line=1'>2</a>\u001b[0m \u001b[39m# we the read the file as shown below.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ludex-learning-dscr350v51k.ws-eu53.gitpod.io/workspace/Learning/AfterWork_Data_Science_Python_for_Data_Analysis.ipynb#ch0000016vscode-remote?line=2'>3</a>\u001b[0m \u001b[39m# \"cities (6).csv\" would be the name of our file.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ludex-learning-dscr350v51k.ws-eu53.gitpod.io/workspace/Learning/AfterWork_Data_Science_Python_for_Data_Analysis.ipynb#ch0000016vscode-remote?line=3'>4</a>\u001b[0m \u001b[39m# ---\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ludex-learning-dscr350v51k.ws-eu53.gitpod.io/workspace/Learning/AfterWork_Data_Science_Python_for_Data_Analysis.ipynb#ch0000016vscode-remote?line=4'>5</a>\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ludex-learning-dscr350v51k.ws-eu53.gitpod.io/workspace/Learning/AfterWork_Data_Science_Python_for_Data_Analysis.ipynb#ch0000016vscode-remote?line=5'>6</a>\u001b[0m cities_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mcities (6).csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ludex-learning-dscr350v51k.ws-eu53.gitpod.io/workspace/Learning/AfterWork_Data_Science_Python_for_Data_Analysis.ipynb#ch0000016vscode-remote?line=7'>8</a>\u001b[0m \u001b[39m# Printing the dataframe\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ludex-learning-dscr350v51k.ws-eu53.gitpod.io/workspace/Learning/AfterWork_Data_Science_Python_for_Data_Analysis.ipynb#ch0000016vscode-remote?line=8'>9</a>\u001b[0m cities_df\n",
            "File \u001b[0;32m/workspace/Learning/.env/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/workspace/Learning/.env/lib/python3.8/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
            "File \u001b[0;32m/workspace/Learning/.env/lib/python3.8/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
            "File \u001b[0;32m/workspace/Learning/.env/lib/python3.8/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
            "File \u001b[0;32m/workspace/Learning/.env/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m     f,\n\u001b[1;32m   1219\u001b[0m     mode,\n\u001b[1;32m   1220\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1221\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1222\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1223\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1224\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1225\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1226\u001b[0m )\n\u001b[1;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
            "File \u001b[0;32m/workspace/Learning/.env/lib/python3.8/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    790\u001b[0m             handle,\n\u001b[1;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    792\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    793\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    794\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    795\u001b[0m         )\n\u001b[1;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cities (6).csv'"
          ]
        }
      ],
      "source": [
        "# Upon selecting and uploading the given file from our computer, \n",
        "# we the read the file as shown below.\n",
        "# \"cities (6).csv\" would be the name of our file.\n",
        "# ---\n",
        "#\n",
        "cities_df = pd.read_csv(\"cities (6).csv\")\n",
        "\n",
        "# Printing the dataframe\n",
        "cities_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EMtq00FfJz4"
      },
      "source": [
        "### <font color=\"green\">Challenges</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzAHrtyxfRS2"
      },
      "outputs": [],
      "source": [
        "# Challenge 1\n",
        "# ---\n",
        "# Question: Create and print a dataframe from a CSV file given the URL below.\n",
        "# ---\n",
        "# Dataset URL = http://bit.ly/TitanicDataset1\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEbocJRCfSg9"
      },
      "outputs": [],
      "source": [
        "# Challenge 2\n",
        "# ---\n",
        "# Question: Create and print a dataframe from the given Excel file found on the given URL.\n",
        "# ---\n",
        "# Dataset URL = http://bit.ly/WindmillDataset\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9m86BizmfS_c"
      },
      "outputs": [],
      "source": [
        "# Challenge 3\n",
        "# ---\n",
        "# Question: Create and print a dataframe from a local file that can be downloaded from the following link.\n",
        "# ---\n",
        "# Dataset Download URL = http://bit.ly/AtaraaDiabetesDataset1\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QelPgwtAbOlI"
      },
      "source": [
        "## 3. Performing Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpCJdHqAkk6k"
      },
      "source": [
        "### Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIkQKFN-eR9Q"
      },
      "outputs": [],
      "source": [
        "# Example 1\n",
        "# ---\n",
        "# Determining the no. of records in the iris dataset.\n",
        "# ---\n",
        "# NB: This dataset was stored in the dataframe df\n",
        "# ---\n",
        "# \n",
        "\n",
        "# Shape returns no. or records/instances and columns/variables\n",
        "#\n",
        "iris_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBxOysIfejkt"
      },
      "outputs": [],
      "source": [
        "# Example 2\n",
        "# ---\n",
        "# Previewing the first few records of the dataframe\n",
        "# NB: head() will give us the first five instances.\n",
        "# You can also specify the no. of desired records by passing \n",
        "# a no. into the function i.e. head(3).\n",
        "# ---\n",
        "# \n",
        "iris_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_HUqgLgevPs"
      },
      "outputs": [],
      "source": [
        "# Example 3\n",
        "# ---\n",
        "# Checking the bottom of the iris_df dataframe \n",
        "# NB: tail() gives us the last 5 records\n",
        "# ---\n",
        "# \n",
        "iris_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5wmuTFulw1t"
      },
      "outputs": [],
      "source": [
        "# Example 4\n",
        "# ---\n",
        "# Checking the datatypes of our columns\n",
        "# ---\n",
        "# float64 - floating point no.\n",
        "# object - strings are store as objects\n",
        "# ---\n",
        "# \n",
        "iris_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0s15pHNeoxf"
      },
      "outputs": [],
      "source": [
        "# Example 5\n",
        "# ---\n",
        "# Bivariate Analysis: Correlation Coefficients\n",
        "# ---\n",
        "# The correlation coefficient is a statistical measure that calculates the strength of the relationship \n",
        "# between the relative movements of two variables. The values range between -1.0 and 1.0. \n",
        "# A correlation of -1.0 shows a perfect negative correlation, while a correlation of 1.0 shows a perfect positive correlation. \n",
        "# A correlation of 0.0 shows no relationship between the movement of the two variables.\n",
        "# ---\n",
        "#\n",
        "\n",
        "# We will first create a correlation matrix \n",
        "# This will give use the correlation values for the different variables.\n",
        "# ---\n",
        "#\n",
        "corr = iris_df.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9cE-w71WZBB"
      },
      "outputs": [],
      "source": [
        "# We can create a heatmap in order to have a visual \n",
        "# of our correlation matrix as shown below\n",
        "# ---\n",
        "\n",
        "# Let's set the size of our visualisation\n",
        "fig, ax = plt.subplots(figsize = (10, 10))\n",
        "\n",
        "# Let's generate a color map to use for our visualisation\n",
        "colormap = sns.diverging_palette(220, 10, as_cmap = True)\n",
        "\n",
        "# Generate heat map, allow annotations and place floats in map\n",
        "sns.heatmap(corr, cmap = colormap, annot = True, fmt = \".2f\")\n",
        "\n",
        "# Apply xticks\n",
        "plt.xticks(range(len(corr.columns)), corr.columns)\n",
        "\n",
        "# Apply yticks\n",
        "plt.yticks(range(len(corr.columns)), corr.columns)\n",
        "\n",
        "# show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAM2IvOCTXjo"
      },
      "source": [
        "From the above heatmap, we can see that variables with a color close to red have a correlation coefficient close to 1. This means the those values have a strong positive correlation. This means that as values of one variables increase, so do the values of the other variable.\n",
        "\n",
        "On the other had variables with a correlation coefficient value close to -1 have a weak negative correlation meaning, when values of one variable increase, then the values of the other variable decrease.\n",
        "\n",
        "Variables with a correlation coefficient close to 0 would either have a weak correlation or if the have a correlation coefficient of 0, then they would have no correlation at all."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoVFeAANfZSA"
      },
      "source": [
        "### <font color=\"green\">Challenges</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kC2Tpjyxfe8j"
      },
      "outputs": [],
      "source": [
        "# Challenge 1\n",
        "# ---\n",
        "# Question: Determining the no. of records in the cities dataset i.e. cities_df\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqHH4ArBfqFa"
      },
      "outputs": [],
      "source": [
        "# Challenge 2\n",
        "# ---\n",
        "# Question: Previewing the first few records of the cities dataset\n",
        "# ---\n",
        "# YOUR CODE GOES HERE\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y27qDx-8frnK"
      },
      "outputs": [],
      "source": [
        "# Challenge 3\n",
        "# ---\n",
        "# Question: Previewing the last few records of the cities dataset\n",
        "# ---\n",
        "# YOUR CODE GOES HERE\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRCw2g9RmMnI"
      },
      "outputs": [],
      "source": [
        "# Challenge 4\n",
        "# ---\n",
        "# Question: Check the data types of the cities dataset\n",
        "# ---\n",
        "# YOUR CODE GOES HERE\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Wsmuo1Zf8R2"
      },
      "outputs": [],
      "source": [
        "# Challenge 5\n",
        "# ---\n",
        "# Question: Determine if there are relationships between the variables in the cities da"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUQgKNf6bTro"
      },
      "source": [
        "## 4. Filtering and Sorting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFOkaq3vXZMh"
      },
      "source": [
        "### Examples and <font color=\"green\">Challenges</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlWrf44NAecP"
      },
      "outputs": [],
      "source": [
        "# Example 4a\n",
        "# ---\n",
        "# Question: Filtering records when columns contain certain values\n",
        "# ---\n",
        "# NB: Filtering records where petal_length is 5.0 \n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "#  \n",
        "\n",
        "# Previewing the first 5 records\n",
        "iris_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CssurHCU2gXU"
      },
      "outputs": [],
      "source": [
        "# Filtering the records where column has certain values \n",
        "# ---\n",
        "#\n",
        "iris_df[iris_df.petal_length.isin(['5.0'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48D2vBZuEukC"
      },
      "outputs": [],
      "source": [
        "# Challenge 4a\n",
        "# ---\n",
        "# Question: From the given dataset, find observations with outlets established in 2002.\n",
        "# ---\n",
        "# Dataset URL = https://bit.ly/ShoprityDS\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQoQq-nfAjL7"
      },
      "outputs": [],
      "source": [
        "# Example 4b\n",
        "# ---\n",
        "# Question: Select records where column doesn't have certain values \n",
        "# in our case, where petal_leghth is not 5.0. We use the \"~\" to specify this.\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "# \n",
        "iris_df[~iris_df.petal_length.isin(['5.0'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5IPcb_bEv_B"
      },
      "outputs": [],
      "source": [
        "# Challenge 4b\n",
        "# ---\n",
        "# Question: Select all the Dairy observations from the given dataset.\n",
        "# ---\n",
        "# Dataset url = https://bit.ly/ShoprityDS\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "# \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDnwO9TSHy3j"
      },
      "outputs": [],
      "source": [
        "# Example 4c\n",
        "# ---\n",
        "# Question: Filter records where petal_width greater than 1.8\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "# \n",
        "iris_df[(iris_df['petal_width'] > 1.8)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYeaoRAIH0vO"
      },
      "outputs": [],
      "source": [
        "# Challenge 4c\n",
        "# ---\n",
        "# Question: Which observations had items outlet sales greater than 2000?\n",
        "# ---\n",
        "# Dataset url = https://bit.ly/ShoprityDS\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "# \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhrdWafVWXkj"
      },
      "outputs": [],
      "source": [
        "# Example 5d\n",
        "# ---\n",
        "# We can also use the query method to get data where petal_width is equal to 1.0.\n",
        "# ---\n",
        "# Once you run this cell, replace the equals operator == to with less than < \n",
        "# or greater than > operators to see their applications as well.\n",
        "# ---\n",
        "# The parameter inplace makes changes in the original dataframe if True.\n",
        "# We should also note the query method works if the column name doesnâ€™t have any empty spaces.\n",
        "# Hence the need replace blank spaces in our column names with '_'\n",
        "# ---\n",
        "#  \n",
        "\n",
        "# Let's filter our data\n",
        "#\n",
        "iris_df.query('petal_width == 1.9', inplace = True) \n",
        "\n",
        "# Previewing our dataset \n",
        "iris_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxqszAhTZCWU"
      },
      "outputs": [],
      "source": [
        "# We can also perform multiple condition filtering as shown below\n",
        "# ---\n",
        "#\n",
        "\n",
        "iris_df.query('sepal_width == 2.7 and petal_length == 5.1', inplace = True) \n",
        "\n",
        "# Previewing our dataset \n",
        "iris_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ngs4-KCdszu"
      },
      "outputs": [],
      "source": [
        "# We can also get the same result as shown below \n",
        "# ---\n",
        "# We use the '&' operator\n",
        "# ---\n",
        "#\n",
        "iris_df[(iris_df.sepal_length == 5.8) & (iris_df.petal_length == 5.1)]\n",
        "\n",
        "# Previewing our dataset \n",
        "iris_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrpXmqvbd_mo"
      },
      "outputs": [],
      "source": [
        "# Challenge 5d\n",
        "# ---\n",
        "# Question: Which observations had items outlet sales greater than 2000 and less than 3000?\n",
        "# ---\n",
        "# Dataset url = https://bit.ly/ShoprityDS\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "# "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC9AVuitZFD8"
      },
      "source": [
        "## 5. Aggregate Functions "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxbUs5stZiZs"
      },
      "source": [
        "### Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crdCNIiaJ9L-"
      },
      "outputs": [],
      "source": [
        "# Loading and previewing the dataset we will use.\n",
        "# ---\n",
        "#\n",
        "ebola_df = pd.read_csv('https://bit.ly/2T60DKG')\n",
        "ebola_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMkqHrLdZiZv"
      },
      "outputs": [],
      "source": [
        "# Checking the size of our dataset.\n",
        "# ---\n",
        "# Dataset URL = https://bit.ly/2T60DKG\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "# \n",
        "liberia_records = ebola_df[ebola_df.Country.isin(['Liberia'])]\n",
        "liberia_records.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mb9r-5uhXRb"
      },
      "outputs": [],
      "source": [
        "# Example 1\n",
        "# ---\n",
        "# Count() Function\n",
        "# ---\n",
        "# How many values do we have accoss our variables in our ebola dataset?\n",
        "# ---\n",
        "#\n",
        "liberia_records = ebola_df[ebola_df.Country.isin(['Liberia'])]\n",
        "liberia_records.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fv0c4tTEZiaB"
      },
      "outputs": [],
      "source": [
        "# Example 2\n",
        "# ---\n",
        "# Unique Occurrences\n",
        "# ---\n",
        "# Were all records in our ebola dataset unique?\n",
        "# ---\n",
        "# \n",
        "ebola_df[ebola_df.duplicated()].shape\n",
        "\n",
        "# Yes, there were no duplicate records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQsRKwb1eeWB"
      },
      "outputs": [],
      "source": [
        "# Example 3\n",
        "# ---\n",
        "# Sum\n",
        "# ---\n",
        "# How many ebola cases in Sierra Leone were reported given the ebola dataset?\n",
        "# ---\n",
        "# \n",
        "sierra_cases_sum = ebola_df[ebola_df.Country.isin(['Sierra Leone'])][['Value']].sum() \n",
        "sierra_cases_sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLSxUtujZGe9"
      },
      "outputs": [],
      "source": [
        "# Example 4\n",
        "# ---\n",
        "# Minimum\n",
        "# ---\n",
        "# Which record had the least no of ebola cases?\n",
        "# ---\n",
        "# \n",
        "least_cases = ebola_df.min()\n",
        "least_cases "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u943169peXFP"
      },
      "outputs": [],
      "source": [
        "# Example 5\n",
        "# ---\n",
        "# Maximum\n",
        "# ---\n",
        "# Which record had the highest no of ebola cases?\n",
        "# ---\n",
        "# \n",
        "highest_cases = ebola_df.max()\n",
        "highest_cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5-TLQHQeYsK"
      },
      "outputs": [],
      "source": [
        "# Example 6\n",
        "# ---\n",
        "# Mean\n",
        "# ---\n",
        "# What was the average number of ebola cases in Sierra Leone?\n",
        "# ---\n",
        "# \n",
        "sierra_cases_avg = ebola_df[ebola_df.Country.isin(['Sierra Leone'])][['Value']].mean() \n",
        "sierra_cases_avg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpX6s0yueecR"
      },
      "outputs": [],
      "source": [
        "# Example 7\n",
        "# ---\n",
        "# Mode\n",
        "# ---\n",
        "# Which country had the most records in the Ebola dataset? \n",
        "# ---\n",
        "# \n",
        "frequent_values_df = ebola_df['Country'].mode() \n",
        "frequent_values_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWpB21E9CiJn"
      },
      "outputs": [],
      "source": [
        "# Example 8\n",
        "# ---\n",
        "# Median\n",
        "# ---\n",
        "# The median value of the Ebola cases.\n",
        "# ---\n",
        "# \n",
        "median_values_df = ebola_df['Value'].median() \n",
        "median_values_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhVsLoBoedbc"
      },
      "outputs": [],
      "source": [
        "# Example 9\n",
        "# ---\n",
        "# Summary Statistics\n",
        "# ---\n",
        "# Create a descriptive statistics table of the given ebola dataset.\n",
        "# ---\n",
        "# \n",
        "ebola_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mUNWEtSZsi9"
      },
      "source": [
        "### <font color=\"green\">Challenges</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-G7d9HyZsi_"
      },
      "outputs": [],
      "source": [
        "# Challenge 1\n",
        "# ---\n",
        "# How many records can be found in the following insurance dataset?\n",
        "# ---\n",
        "# Insurance Dataset url = https://bit.ly/2y5CRYc\n",
        "# ---\n",
        "# This dataset contains anonymised patient data.\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl1KEjeoZsjB"
      },
      "outputs": [],
      "source": [
        "# Challenge 2\n",
        "# ---\n",
        "# Are there any duplicates in the insurance dataset?\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDj1GABnZsjD"
      },
      "outputs": [],
      "source": [
        "# Challenge 3\n",
        "# ---\n",
        "# Which regions did the patients come from?\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAtrNHs824ay"
      },
      "outputs": [],
      "source": [
        "# Challenge 4\n",
        "# ---\n",
        "# What was the highest bmi recorded for patients from northwest and southwest regions?\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsloZ4Bo24P1"
      },
      "outputs": [],
      "source": [
        "# Challenge 5\n",
        "# ---\n",
        "# What was the youngest age of a patient?\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XffQqHOd24KD"
      },
      "outputs": [],
      "source": [
        "# Challenge 6\n",
        "# ---\n",
        "# What was the average bmi recorded for patients above 50 years old?\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IULqwYi235v"
      },
      "outputs": [],
      "source": [
        "# Challenge 7\n",
        "# ---\n",
        "# How much was spent collectively by male and female patients?\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XZbcORGZLd0"
      },
      "source": [
        "## 6. Pivot Tables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xldYtGZ-Zjz5"
      },
      "source": [
        "### Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlfAgV7qJQoA"
      },
      "outputs": [],
      "source": [
        "# Loading and previewing the dataset that we will use\n",
        "# ---\n",
        "#\n",
        "insurance_df = pd.read_csv('https://bit.ly/2y5CRYc')\n",
        "insurance_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyNlcAEhZjz6"
      },
      "outputs": [],
      "source": [
        "# Example 1\n",
        "# ---\n",
        "# A pivot table is a summary table and comprises of \n",
        "# outcomes similar to the group by tables.\n",
        "# --- \n",
        "# We will start working with pivot tables by getting one column \n",
        "# and applying an aggregate function as shown below\n",
        "# ---\n",
        "# \n",
        "pd.pivot_table(insurance_df, index=['region'], aggfunc='mean')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9eEtnPKZjz-"
      },
      "outputs": [],
      "source": [
        "# Example 2\n",
        "# ---\n",
        "# Getting the first entry for each gender.\n",
        "# NB: You can get the last one too using last().\n",
        "# In addition, note the that the columns have been arranged alphabetically.\n",
        "# ---\n",
        "# \n",
        "pd.pivot_table(insurance_df, index=['sex'], aggfunc='first')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XncXWHbLxNqv"
      },
      "outputs": [],
      "source": [
        "# Example 3\n",
        "# ---\n",
        "# We can group a single column by another column then apply an aggregate function as shown\n",
        "# ---\n",
        "# We will use numpy to compute the mean\n",
        "#\n",
        "pd.pivot_table(insurance_df, index=['sex'], aggfunc={'expenses': np.mean})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ek2sW9X2zqwz"
      },
      "outputs": [],
      "source": [
        "# Example 4\n",
        "# ---\n",
        "# Grouping region by another column i.e. bmi, applying an aggregate function\n",
        "# ---\n",
        "#\n",
        "pd.pivot_table(insurance_df, index=['region'], aggfunc={'bmi': np.mean})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfOhsM1I0bNu"
      },
      "outputs": [],
      "source": [
        "# Example 5\n",
        "# ---\n",
        "# Using a pivote table, we can also create a summary statistical table as shown below\n",
        "# ---\n",
        "#\n",
        "pd.pivot_table(insurance_df, index=['region'], aggfunc={'expenses': 'describe'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_brcCVY3gHq"
      },
      "outputs": [],
      "source": [
        "# Example 6\n",
        "# ---\n",
        "# Getting the no. of children in each region\n",
        "# ---\n",
        "#  \n",
        "# \n",
        "pd.pivot_table(insurance_df, index=['region'], aggfunc={'children': sum}) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldDrVxC54Al8"
      },
      "outputs": [],
      "source": [
        "# Example 6\n",
        "# ---\n",
        "# Applying multiple aggregate functions to a group\n",
        "# ---\n",
        "# \n",
        "pd.pivot_table(insurance_df, index=['region', 'sex'], aggfunc={'expenses': [min, max, sum]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1HkBiWr51y6"
      },
      "outputs": [],
      "source": [
        "# Example 7\n",
        "# ---\n",
        "# Applying multiple aggregate functions to a group\n",
        "# ---\n",
        "# \n",
        "pd.pivot_table(insurance_df, index=['region', 'sex'], aggfunc={'expenses': sum})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9c7In767vRZ"
      },
      "source": [
        "### <font color=\"green\">Challenges</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDtAMSQd7y3B"
      },
      "source": [
        "The challenges in this section will be same as the ones group by challenges. Compare your solutions with the ones you got in the previous section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8U-l2XmL7vRd"
      },
      "outputs": [],
      "source": [
        "# You will use the supermarket dataset you previously used. \n",
        "# ---\n",
        "# The dataset contains customer invoice data.\n",
        "# ---\n",
        "# Dataset url = https://bit.ly/SuperMarketSalesDB\n",
        "# ---\n",
        "#  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQ47XAX67vRm"
      },
      "outputs": [],
      "source": [
        "# Challenge 1\n",
        "# ---\n",
        "# Question: What was the average tax per city?\n",
        "# ---\n",
        "# OUR CODE GOES BELOW \n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M54iMgRt7vRv"
      },
      "outputs": [],
      "source": [
        "# Challenge 2\n",
        "# ---\n",
        "# Question: How much did female members from the city of Yagon spend?\n",
        "# ---\n",
        "# OUR CODE GOES BELOW \n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7ua8NHY7vSI"
      },
      "outputs": [],
      "source": [
        "# Challenge 3\n",
        "# ---\n",
        "# Question: How much was spent across all cities?\n",
        "# ---\n",
        "# OUR CODE GOES BELOW \n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4Cdnyqb7vSN"
      },
      "outputs": [],
      "source": [
        "# Challenge 4\n",
        "# ---\n",
        "# Question: What was the sum of goods sold across all branches?\n",
        "# ---\n",
        "# OUR CODE GOES BELOW \n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiqXSy4Q7vSS"
      },
      "outputs": [],
      "source": [
        "# Challenge 5\n",
        "# ---\n",
        "# Question: Which branches collected the most amount of money? \n",
        "# ---\n",
        "# OUR CODE GOES BELOW \n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXKJv3tW7vSY"
      },
      "outputs": [],
      "source": [
        "# Challenge 6\n",
        "# ---\n",
        "# Question: Which were the top rated branches?\n",
        "# ---\n",
        "# OUR CODE GOES BELOW \n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MF7tVGR7vSd"
      },
      "outputs": [],
      "source": [
        "# Challenge 7\n",
        "# ---\n",
        "# Question: Make a comparison between non-members who made cash payments and credit card payments.\n",
        "# ---\n",
        "# OUR CODE GOES BELOW \n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_YYoGhh7vSj"
      },
      "outputs": [],
      "source": [
        "# Challenge 8\n",
        "# ---\n",
        "# Question: Show the products line that sold the most indicating the rating.\n",
        "# ---\n",
        "# OUR CODE GOES BELOW \n",
        "# "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "pcxusFFvAC4A",
        "GH7mXeCSkq0h",
        "aQKL2Y8uksQX",
        "Q2e7YkLzWW0G",
        "bz-KdKO3fLjt",
        "5EMtq00FfJz4",
        "QelPgwtAbOlI",
        "IpCJdHqAkk6k",
        "eoVFeAANfZSA",
        "eUQgKNf6bTro",
        "FFOkaq3vXZMh",
        "YC9AVuitZFD8",
        "UxbUs5stZiZs",
        "1mUNWEtSZsi9",
        "6XZbcORGZLd0",
        "xldYtGZ-Zjz5",
        "q9c7In767vRZ"
      ],
      "include_colab_link": true,
      "name": "AfterWork Data Science: Python for Data Analysis ",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('.env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "a6bc3ddd5ef912eb080082270d90875aae86122707e05d41460d04de85d93f84"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
